{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import plotly.express as px\n",
    "from jaxtyping import Float\n",
    "from functools import partial\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/cole/cs2822r/saes2822r/access.tok\", \"r\") as file:\n",
    "    access_token = file.read()\n",
    "    login(token=access_token)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset  \n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt-2-small (for testing)\n",
    "model = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# load sae on res stream of gpt-2-small, plus cfg and sparsity val (for testing)\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"gpt2-small-res-jb\",\n",
    "    sae_id = \"blocks.7.hook_resid_pre\",\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae.use_error_term\n",
    "\n",
    "top_neurons = {}\n",
    "\n",
    "for example in negative_set:\n",
    "    _, cache = model.run_with_cache_with_saes(example, saes=[sae])\n",
    "\n",
    "    # print the top 5 features and how much they fired\n",
    "    vals, inds = torch.topk(cache['blocks.7.hook_resid_pre.hook_sae_acts_post'][0, -1, :], 15)\n",
    "    for val, ind in zip(vals, inds):\n",
    "        print(f\"Feature {ind} fired {val:.2f}\")\n",
    "        html = get_dashboard_html(sae_release = \"gpt2-small\", sae_id=\"7-res-jb\", feature_idx=ind)\n",
    "        display(IFrame(html, width=800, height=400))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
